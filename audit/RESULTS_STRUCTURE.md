# Results Directory Structure

This document describes the comprehensive output structure generated by the Offshore Riser ML Pipeline.

**Parquet-first outputs:** All core artifacts are written as `.parquet` for speed and size. Optional Excel sidecars (`.xlsx`) are produced only when `outputs.save_excel_copy` is `True` (default: `False`). File names below use the `.parquet` extension; when Excel sidecars are enabled, an `.xlsx` copy with the same base name is also written.

## Overview

Each pipeline run creates a timestamped or named results directory with the following structure:

```
results_<TargetVar>_<Model>_<Config>/
├── 00_CONFIG/                    # Configuration & Runtime Metadata
├── 01_DATA_VALIDATION/           # Data Quality Checks
├── 01_GLOBAL_TRACKING/           # Cross-Round Evolution Metrics
├── 02_SMART_SPLIT/              # Train/Val/Test Splits
├── 13_REPRODUCIBILITY_PACKAGE/  # Self-Contained Reproduction Artifacts
└── ROUND_XXX/                    # Per-Round RFE Results (000-NNN)
```

---

## Top-Level Directories

### 00_CONFIG

**Purpose:** Configuration snapshots and runtime metadata for auditability and reproducibility.

**Contents:**
- `config_used.json` - Full configuration with all resolved defaults
- `config_hash.txt` - SHA256 hash of configuration for uniqueness validation
- `run_metadata.json` - Execution metadata (timestamp, system info, git hash)
- `schema.json` - JSON schema used for config validation

**Use Cases:**
- Verify exact configuration used for a run
- Compare configurations across runs
- Validate reproducibility

---

### 01_DATA_VALIDATION

**Purpose:** Data quality assurance reports and validation artifacts.

**Contents:**
- `validated_data.parquet` - Full dataset after validation and enrichment (optional Excel sidecar)
- `column_stats.parquet` - Statistical summary of all numeric columns (optional Excel sidecar)
- `sin_cos_validation.parquet` - Geometric constraint validation (sin² + cos² ≈ 1) (optional Excel sidecar)
- `angle_distribution.png` - Histogram of angle distribution
- `hs_distribution.png` - Histogram of wave height (Hs) distribution

**Validation Checks:**
- Required column presence
- NaN/Inf detection
- Circle constraint verification (for directional data)
- Derived column computation (bins for stratification)

---

### 01_GLOBAL_TRACKING

**Purpose:** Cross-round performance evolution and feature importance tracking.

**Contents:**

#### 01_metrics/
- `global_evolution_metrics.parquet` - Round-by-round metric progression (optional Excel sidecar)
- `cumulative_dropped_features.parquet` - Feature elimination history (optional Excel sidecar)

#### 02_features/
- `feature_importance_evolution.parquet` - Feature importance across rounds (optional Excel sidecar)
- `feature_retention_timeline.csv` - Feature survival timeline

#### 04_evolution_plots/
- `metric_evolution.png` - Line plots of metrics over rounds
- `feature_count_progression.png` - Feature count reduction
- `performance_vs_complexity.png` - Pareto frontier visualization

**Insights Provided:**
- Performance degradation points
- Feature importance trends
- Optimal round identification
- Complexity-accuracy tradeoffs

---

### 02_SMART_SPLIT

**Purpose:** Train/validation/test split artifacts with stratification verification.

**Contents:**
- `train.parquet` - Training split (optional Excel sidecar)
- `val.parquet` - Validation split (optional Excel sidecar)
- `test.parquet` - Test split (optional Excel sidecar)
- `split_balance_report.parquet` - Stratification quality metrics (optional Excel sidecar)
- `split_hs_dist.png` - Hs distribution comparison across splits
- `split_angle_dist.png` - Angle distribution comparison across splits

**Stratification Strategy:**
- Angle bins × Hs bins = combined stratification key
- Ensures representative samples across all operational conditions

---

### 13_REPRODUCIBILITY_PACKAGE

**Purpose:** Self-contained package for reproducing exact results.

**Contents:**
- `config.json` - Configuration snapshot
- `requirements_frozen.txt` - Exact package versions (pip freeze)
- `system_info.json` - Hardware, OS, Python version, CPU info
- `run_metadata.json` - Git commit hash, timestamp, user
- `README.md` - Instructions for reproduction
- `diagnostics/` - System diagnostics and compatibility checks

**Reproduction Steps (from README):**
1. Create identical Python environment
2. Install frozen requirements
3. Verify system compatibility
4. Run pipeline with provided config
5. Compare checksums

---

## Per-Round Structure (ROUND_XXX)

Each RFE round creates a comprehensive analysis directory:

```
ROUND_000/
├── 00_DATASETS/                           # Feature Lists & Checksums
├── 01_GRID_SEARCH/                        # HPO Results
│   ├── 01_INITIAL_TRIALS/
│   ├── 02_DETAILED_SEARCH/
│   └── 03_HYPERPARAMETER_OPTIMIZATION/
├── 02_HYPERPARAMETER_ANALYSIS/            # HPO Analysis Reports
├── 03_BASE_MODEL_RESULTS/                 # Baseline Model Performance
├── 04_FEATURE_EVALUATION/                 # LOFO Analysis
├── 05_DROPPED_FEATURE_RESULTS/            # Dropped Feature Model
├── 06_COMPARISON/                         # Baseline vs. Dropped Comparison
└── _ROUND_COMPLETE.flag                   # Round completion marker
```

---

### 00_DATASETS

**Purpose:** Feature list tracking with integrity validation.

**Contents:**
- `feature_list.json` - Active features for this round (with metadata)
- `feature_list_checksum.txt` - SHA256 checksum for validation
- Feature list includes:
  - `features`: List of feature names
  - `count`: Number of features
  - `round`: Round number
  - `timestamp`: Creation timestamp

**Checksum Validation:**
- Prevents feature list corruption
- Validates consistency across round transitions
- Enables atomic feature list updates

---

### 01_GRID_SEARCH

**Purpose:** Hyperparameter optimization (HPO) results.

**Structure:**
```
01_GRID_SEARCH/
├── 01_INITIAL_TRIALS/
│   ├── trial_results.parquet  # Optional Excel sidecar when enabled
│   └── trial_predictions/
├── 02_DETAILED_SEARCH/
│   └── search_results.parquet  # Optional Excel sidecar when enabled
└── 03_HYPERPARAMETER_OPTIMIZATION/
    ├── results/
    │   ├── all_configurations.parquet  # Optional Excel sidecar when enabled
    │   ├── best_configuration.json
    │   └── optimization_summary.parquet  # Optional Excel sidecar when enabled
    ├── predictions/
    └── visualizations/
```

**Key Files:**
- `all_configurations.parquet` - All HPO trials with metrics (optional Excel sidecar)
- `best_configuration.json` - Optimal hyperparameters
- `optimization_summary.parquet` - Statistical summary of search (optional Excel sidecar)

---

### 02_HYPERPARAMETER_ANALYSIS

**Purpose:** Advanced HPO analysis and sensitivity plots.

**Contents:**
- `parameter_importance.parquet` - Hyperparameter sensitivity ranking (optional Excel sidecar)
- `interaction_matrix.parquet` - Parameter interaction effects (optional Excel sidecar)
- `sensitivity_plots/` - Individual parameter response curves
- `correlation_heatmap.png` - Parameter correlation visualization

**Analyses:**
- Univariate sensitivity
- Bivariate interactions
- Parameter importance ranking
- Optimization landscape visualization

---

### 03_BASE_MODEL_RESULTS

**Purpose:** Baseline model trained with ALL current active features.

**Contents:**
- `baseline_predictions_val.parquet` - Validation predictions (optional Excel sidecar)
- `baseline_predictions_test.parquet` - Test predictions (optional Excel sidecar)
- `baseline_metrics_val.parquet` - Validation metrics (optional Excel sidecar)
- `baseline_metrics_test.parquet` - Test metrics (optional Excel sidecar)
- `error_analysis_test/` - Detailed error analysis
  - `error_by_angle_bin.parquet` (optional Excel sidecar)
  - `error_by_hs_bin.parquet` (optional Excel sidecar)
  - `error_statistics.parquet` (optional Excel sidecar)
  - `worst_predictions.parquet` (optional Excel sidecar)
- `diagnostics/` - Diagnostic plots
  - `residual_plots.png`
  - `qq_plot.png`
  - `error_distribution.png`

---

### 04_FEATURE_EVALUATION

**Purpose:** Leave-One-Feature-Out (LOFO) analysis results.

**Contents:**
- `lofo_summary.parquet` - Comprehensive LOFO results table (optional Excel sidecar)
  - Columns: feature, val_cmae, test_cmae, delta_val_cmae, delta_test_cmae
  - All accuracy bands and component metrics
- `lofo_impact_plots/` - Visual ranking of feature importance
  - `lofo_impact_barplot.png`
  - `lofo_delta_cmae.png`

**Interpretation:**
- Features with LOWEST CMAE when dropped → highest importance
- Negative delta_cmae → dropping improves performance (remove!)
- Positive delta_cmae → dropping degrades performance (keep)

---

### 05_DROPPED_FEATURE_RESULTS

**Purpose:** Results from model with the selected feature removed.

**Contents:**
- `dropped_predictions_val.parquet` - Validation predictions without feature (optional Excel sidecar)
- `dropped_predictions_test.parquet` - Test predictions without feature (optional Excel sidecar)
- `error_analysis/` - Error analysis for dropped model
- `diagnostics/` - Diagnostic plots for dropped model

**Purpose:**
- Verify LOFO predictions
- Detailed characterization of dropped feature impact
- Support decision validation

---

### 06_COMPARISON

**Purpose:** Detailed comparison between baseline and dropped-feature models.

**Contents:**
- `comparison_summary.parquet` - Metric differences table (optional Excel sidecar)
- `comparison_plots/` - Visual comparisons
  - `metric_comparison_barplot.png`
  - `prediction_scatter.png`
  - `error_distribution_comparison.png`
  - `residual_comparison.png`

**Insights:**
- Performance delta quantification
- Error pattern changes
- Model behavior differences

---

### _ROUND_COMPLETE.flag

**Purpose:** Round completion marker with state validation.

**JSON Contents:**
```json
{
  "timestamp": "2025-12-10T14:23:45",
  "round": 0,
  "dropped_feature": "feature_X",
  "features_remaining": 166,
  "stopping_status": "CONTINUE",
  "next_round_feature_checksum": "abc123...",
  "next_round_feature_count": 166
}
```

**Use Cases:**
- Resume capability (crash recovery)
- Round state validation
- Feature list integrity checking
- Stopping criteria tracking

**Stopping Status Values:**
- `"CONTINUE"` - Proceed to next round
- `"Minimum Feature Count Reached"` - Hit min_features threshold
- `"Maximum Rounds Reached"` - Hit max_rounds limit
- `"Performance Degradation > 10%"` - Metric degraded beyond threshold

---

## Workflow Example

### Typical Pipeline Flow

1. **Start Pipeline**
   - Creates `00_CONFIG/` and `01_DATA_VALIDATION/`
   - Performs data loading and validation
   - Creates `02_SMART_SPLIT/` with stratified splits

2. **Round 000**
   - HPO search → `ROUND_000/01_GRID_SEARCH/`
   - Train baseline → `ROUND_000/03_BASE_MODEL_RESULTS/`
   - LOFO analysis → `ROUND_000/04_FEATURE_EVALUATION/`
   - Select feature to drop → `ROUND_000/05_DROPPED_FEATURE_RESULTS/`
   - Compare models → `ROUND_000/06_COMPARISON/`
   - Update global tracker → `01_GLOBAL_TRACKING/`
   - Mark complete → `ROUND_000/_ROUND_COMPLETE.flag`

3. **Round 001** (with 1 fewer feature)
   - Repeat steps from Round 000
   - Continue until stopping criteria met

4. **Finalization**
   - Create `13_REPRODUCIBILITY_PACKAGE/`
   - Generate final reports

---

## Key Metrics Tracked

### Circular Metrics (Primary)
- **CMAE** (Circular Mean Absolute Error) - Primary optimization metric
- **CRMSE** (Circular Root Mean Squared Error)

### Accuracy Bands
- `accuracy_at_0deg` - Exact predictions
- `accuracy_at_5deg` - Within 5° tolerance
- `accuracy_at_10deg` - Within 10° tolerance
- `accuracy_at_20deg` - Within 20° tolerance

### Component Metrics
- `mae_sin`, `rmse_sin` - Sin component errors
- `mae_cos`, `rmse_cos` - Cos component errors

### Error Statistics
- `max_error` - Worst prediction error
- `mean_error` - Bias (signed error)
- `std_error` - Error standard deviation
- `median_abs_error` - Median absolute error
- Percentiles: 50th, 75th, 90th, 95th, 99th

---

## File Format Conventions

### Parquet Files (.parquet)
- Primary format for all tabular data (fast, columnar, compressed)
- Default saves exclude the index for clean tables
- Recommended for downstream analysis and storage

### Optional Excel Sidecars (.xlsx)
- Created only when `outputs.save_excel_copy` is enabled
- Human-friendly copies with the same base filename as the Parquet file
- Useful for quick inspection; not required for pipeline consumption

### JSON Files (.json)
- Configuration, metadata, and structured data
- Indented (2 spaces) for readability
- UTF-8 encoded

### Plots (.png)
- 300 DPI for publication quality
- Matplotlib with 'Agg' backend (non-interactive)
- Descriptive filenames

---

## Data Persistence Strategy

### Asynchronous Writes
- Optional Excel sidecars can be written asynchronously (utils.file_io.AsyncFileWriter)
- Prevents I/O blocking during computation when Excel copies are enabled
- Parquet writes remain the primary, fastest path and are synchronous

### Atomic Operations
- Feature lists updated atomically (temp file + rename)
- Prevents corruption from crashes
- Checksum validation on load

---

## Directory Naming Conventions

### Results Root
- Format: `results_<TargetVar>_<Model>_<Strategy>_<Features>`
- Example: `results_RiserAngle_ExtraTrees_RFE_167_to_1`
- Components:
  - `TargetVar` - Prediction target (e.g., RiserAngle)
  - `Model` - Algorithm (e.g., ExtraTrees, RandomForest)
  - `Strategy` - Pipeline type (e.g., RFE, HPO, GridSearch)
  - `Features` - Feature range (e.g., 167_to_1)

### Round Directories
- Format: `ROUND_XXX` (zero-padded to 3 digits)
- Example: `ROUND_000`, `ROUND_015`, `ROUND_142`

### Phase Directories
- Format: `NN_PHASE_NAME` (two-digit prefix for sorting)
- Examples:
  - `00_CONFIG`
  - `01_DATA_VALIDATION`
  - `13_REPRODUCIBILITY_PACKAGE`

---

## Resumption & Crash Recovery

The pipeline supports resuming from crashes:

1. **Detection:** Checks for `_ROUND_COMPLETE.flag` in each round directory
2. **Validation:** Verifies feature list checksums
3. **Resume:** Loads round state and continues from next round
4. **Integrity:** Ensures no data corruption via checksum validation

**Resume Flow:**
```python
if (_ROUND_COMPLETE.flag exists):
    load_flag_data()
    validate_checksums()
    load_feature_list()
    continue_to_next_round()
else:
    execute_current_round()
```

---

## Storage Estimates

### Typical Run (167→1 features, 8 rounds)

| Component | Size | Notes |
|-----------|------|-------|
| Data Validation | 50-100 MB | Validated datasets + plots |
| Per Round | 200-500 MB | HPO results, predictions, plots |
| Global Tracking | 10-20 MB | Evolution metrics |
| Reproducibility | 5-10 MB | Config + system info |
| **Total** | **1.5-4 GB** | For full RFE run |

### Large Runs (1000+ features, 50+ rounds)
- Estimate: 20-50 GB
- Consider:
  - Parquet format for large datasets
  - Selective artifact saving
  - Compression options

---

## Best Practices

### During Development
1. Use descriptive run names
2. Save config snapshots before modifications
3. Review `01_GLOBAL_TRACKING/` for performance trends
4. Check `_ROUND_COMPLETE.flag` for successful completion

### For Production
1. Enable all reproducibility features
2. Verify checksums before critical decisions
3. Archive complete results directories
4. Document any manual interventions

### For Debugging
1. Check `error_analysis/` for outlier patterns
2. Review `lofo_summary.parquet` (optional Excel sidecar) for feature insights
3. Compare `06_COMPARISON/` for feature impact
4. Examine `diagnostics/` plots for model behavior

---

## Maintenance

### Cleanup Old Runs
```bash
# Archive runs older than 30 days
find results_* -type d -mtime +30 -exec tar -czf {}.tar.gz {} \;

# Remove archived directories
find results_* -type d -mtime +30 -exec rm -rf {} \;
```

### Verify Integrity
```python
# Check all feature list checksums
python -m modules.rfe.rfe_controller --verify-checksums

# Validate reproducibility packages
python -m modules.reproducibility_engine --validate-all
```

---

## Related Documentation

- [README.md](./README.md) - Main project documentation
- [audit/00_INDEX.md](./audit/00_INDEX.md) - Code quality audit
- [config/schema.json](./config/schema.json) - Configuration schema
- [CONTRIBUTING.md](./CONTRIBUTING.md) - Development guide

---

**Last Updated:** 2025-12-10
**Pipeline Version:** 2.0
**Maintainer:** Offshore Riser ML Team
